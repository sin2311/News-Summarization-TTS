# -*- coding: utf-8 -*-
"""cron.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jvbSpikw-b_EXjcay0LRcCSyD0OhpO70
"""

from google.colab import files

# Upload multiple files
uploaded = files.upload()

!ls

!mkdir -p utils  # Create the 'utils' directory

# Move files into the 'utils' directory
!mv utils_text_to_speech.py utils/text_to_speech.py
!mv utils_gemini_service.py utils/gemini_service.py
!mv utils_news_scraper.py utils/news_scraper.py

# Commented out IPython magic to ensure Python compatibility.
# %%writefile cron.py
# 
# import pandas as pd
# import pickle
# from utils.news_scraper import get_news_articles
# from utils.gemini_service import process_articles
# 
# # Define output directory
# OUTPUT_DIR = "data/output/"
# COMPANY_LIST_FILE = "/content/company_list.csv"
# 
# def run_cron():
#     """Fetch news for companies, process sentiment, and save results."""
#     # Read company names from CSV
#     companies = pd.read_csv(COMPANY_LIST_FILE)["Company"].tolist()
# 
#     for company in companies:
#         print(f"\nüöÄ Fetching news for: {company}")
#         articles = get_news_articles(company)
# 
#         if not articles:
#             print(f"‚ùå No articles found for {company}")
#             continue
# 
#         # Process sentiment & summarization
#         result = process_articles(company, articles)
# 
#         # Save results as a pickle file
#         output_file = f"{OUTPUT_DIR}/{company.lower()}.pkl"
#         with open(output_file, "wb") as f:
#             pickle.dump(result, f)
# 
#         print(f"‚úÖ Data saved: {output_file}")
# 
# if __name__ == "__main__":
#     run_cron()
#

!pip install newspaper3k

!pip install lxml[html_clean] lxml_html_clean

import os

# Define the path where you want to save the file
output_dir = 'data/output/'

# Check if the directory exists, and if not, create it
if not os.path.exists(output_dir):
    os.makedirs(output_dir)
    print(f"Created directory: {output_dir}")

# Now you can proceed with saving your file
file_path = os.path.join(output_dir, 'google.pkl')
# Your code that saves the file to file_path

!python cron.py

import pickle

file_path = '/content/data/output/apple.pkl'

with open(file_path, 'rb') as f:
    loaded_data = pickle.load(f)

print(f"Loaded data: {loaded_data}")